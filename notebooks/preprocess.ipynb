{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_TO_ALLOWED_DEP_KINDS_LUT = {\n",
    "    \"bioconductor\": [\"imports\", \"depends\"],\n",
    "    \"cran\": [\"imports\", \"depends\"],\n",
    "    \"pypi\": [\"runtime\", \"python_version\"],\n",
    "}\n",
    "\n",
    "REGISTRY_TO_NORM_PAKCAGE_NAME_LUT = {\n",
    "    \"bioconductor\": False,\n",
    "    \"cran\": False,\n",
    "    \"pypi\": True,\n",
    "}\n",
    "\n",
    "def norm_package_name(name: str) -> str:\n",
    "    lowered = name.lower()\n",
    "    no_hyphen_or_period = lowered.replace(\"-\", \"_\").replace(\".\", \"_\")\n",
    "    full_norm = re.sub(\n",
    "        r\"([a-z0-9\\_]+)(\\>|\\<|\\!|\\=|\\[){0,1}(.)*\",\n",
    "        r\"\\1\",\n",
    "        no_hyphen_or_period,\n",
    "    )\n",
    "    return full_norm\n",
    "\n",
    "def process_package(\n",
    "    df: pd.DataFrame,\n",
    "    package_details: pd.Series,\n",
    "    graph: nx.DiGraph,\n",
    "    processed_nodes: set,\n",
    "    allowed_dep_kinds: list[str] | None = None,\n",
    "    do_norm_package_name: bool = False,\n",
    "    depth: int = 0,\n",
    "    print_depth: bool = False,\n",
    "):\n",
    "    # Handle no ecosystem\n",
    "    if package_details[\"ecosystem\"] is None:\n",
    "        return\n",
    "\n",
    "    # Get normed package name\n",
    "    if do_norm_package_name:\n",
    "        package_name = norm_package_name(package_details[\"name\"])\n",
    "    else:\n",
    "        package_name = package_details[\"name\"]\n",
    "    \n",
    "    # Handle printing\n",
    "    if print_depth:\n",
    "        print(\"\\t\" * depth + package_name)\n",
    "\n",
    "    # Create node if package not in graph\n",
    "    if package_name not in processed_nodes:\n",
    "        graph.add_node(\n",
    "            package_name,\n",
    "            czi_id=package_details.czi_id,\n",
    "            keywords=\", \".join(package_details.keywords_array),\n",
    "            mentions_count=package_details.mentions_count,\n",
    "            ecosystem=package_details.ecosystem,\n",
    "        )\n",
    "        processed_nodes.add(package_name)\n",
    "\n",
    "    # For each dependency in the \"latest_version\" column\n",
    "    this_node_deps = set()\n",
    "    for dep in package_details.latest_version[\"dependencies\"]:\n",
    "        if dep is not None and dep[\"package_name\"] is not None:\n",
    "            # Get dep name\n",
    "            if do_norm_package_name:\n",
    "                dep_name = norm_package_name(dep[\"package_name\"])\n",
    "            else:\n",
    "                dep_name = dep[\"package_name\"]\n",
    "            \n",
    "            # Get dep kind\n",
    "            dep_kind = str(dep[\"kind\"])\n",
    "\n",
    "            # If its not allowed\n",
    "            if allowed_dep_kinds is None or dep_kind in allowed_dep_kinds:\n",
    "                # Handle not in graph\n",
    "                if dep_name not in processed_nodes:\n",
    "                    dep_details = df[df[\"name\"] == dep_name]\n",
    "                    if len(dep_details) == 1:\n",
    "                        dep_details = dep_details.iloc[0]\n",
    "                        result = process_package(\n",
    "                            df,\n",
    "                            dep_details,\n",
    "                            graph,\n",
    "                            processed_nodes,\n",
    "                            depth=depth+1,\n",
    "                            print_depth=print_depth,\n",
    "                            do_norm_package_name=do_norm_package_name,\n",
    "                            allowed_dep_kinds=allowed_dep_kinds,\n",
    "                        )\n",
    "\n",
    "                        # Check if the node _should_ be added\n",
    "                        if result is not None:\n",
    "                            this_node_deps.add(dep_name)\n",
    "\n",
    "                    elif len(dep_details) > 1:\n",
    "                        raise ValueError(f\"multiple packages with name: '{dep_name}'\")\n",
    "    \n",
    "    # Add edges\n",
    "    for dep_name in this_node_deps:\n",
    "        graph.add_edge(package_name, dep_name)\n",
    "\n",
    "    return True\n",
    "\n",
    "def graph_from_registry(\n",
    "    registry: pd.DataFrame,\n",
    "    registry_name: str,\n",
    "    outfile: str,\n",
    "    print_depth: bool = False,\n",
    "):\n",
    "    # Create graph management\n",
    "    graph = nx.DiGraph()\n",
    "    processed_nodes = set()\n",
    "    for _, row in tqdm(registry.iterrows(), total=len(registry)):\n",
    "        process_package(\n",
    "            registry,\n",
    "            row,\n",
    "            graph,\n",
    "            processed_nodes,\n",
    "            allowed_dep_kinds=REGISTRY_TO_ALLOWED_DEP_KINDS_LUT[registry_name],\n",
    "            do_norm_package_name=REGISTRY_TO_NORM_PAKCAGE_NAME_LUT[registry_name],\n",
    "            print_depth=print_depth,\n",
    "        )\n",
    "    \n",
    "    nx.write_gexf(graph, outfile)\n",
    "\n",
    "def graph_from_czi_ids(\n",
    "    registries: dict[str, pd.DataFrame],\n",
    "    czi_ids: list[str],\n",
    "    print_depth: bool = False,\n",
    "    starting_node: str | None = None,\n",
    "    starting_node_attrs: dict[str, str] | None = None,\n",
    "    graph: nx.DiGraph | None = None,\n",
    "    processed_nodes: set[str] | None = None,\n",
    "):\n",
    "    # Init graph and storage\n",
    "    if graph is None:\n",
    "        graph = nx.DiGraph()\n",
    "    if processed_nodes is None:\n",
    "        processed_nodes = set()\n",
    "\n",
    "    # If starting node\n",
    "    if starting_node:\n",
    "        graph.add_node(\n",
    "            starting_node,\n",
    "            **starting_node_attrs,\n",
    "        )\n",
    "    \n",
    "    # For each czi_id\n",
    "    for registry_name, registry in registries.items():\n",
    "        for czi_id in czi_ids:\n",
    "            package_of_interest = registry.loc[registry.czi_id == czi_id]\n",
    "            if len(package_of_interest) == 1:\n",
    "                # Actual get\n",
    "                package_of_interest = package_of_interest.iloc[0]\n",
    "\n",
    "                # Get normed name for package\n",
    "                if REGISTRY_TO_NORM_PAKCAGE_NAME_LUT[registry_name]:\n",
    "                    package_name = norm_package_name(package_of_interest[\"name\"])\n",
    "                else:\n",
    "                    package_name = package_of_interest[\"name\"]\n",
    "\n",
    "                # Create graph just for this package\n",
    "                result = process_package(\n",
    "                    registry,\n",
    "                    package_of_interest,\n",
    "                    graph,\n",
    "                    processed_nodes,\n",
    "                    allowed_dep_kinds=REGISTRY_TO_ALLOWED_DEP_KINDS_LUT[registry_name],\n",
    "                    do_norm_package_name=REGISTRY_TO_NORM_PAKCAGE_NAME_LUT[registry_name],\n",
    "                    print_depth=print_depth,\n",
    "                )\n",
    "\n",
    "                if result is not None and starting_node is not None:\n",
    "                    # Add edges from start node to processed\n",
    "                    graph.add_edge(starting_node, package_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_registry(registry_path: str) -> pd.DataFrame:\n",
    "    # Read in data\n",
    "    df = pd.read_json(registry_path, lines=True)\n",
    "    df.czi_id = df.czi_id.astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "# load all registries\n",
    "registries = {\n",
    "    \"pypi\": load_registry(\"../data/pypi_with_mentions.ndjson\"),\n",
    "    \"cran\": load_registry(\"../data/cran_with_mention_counts.ndjson\"),\n",
    "    \"bioconductor\": load_registry(\"../data/bioconductor_with_mention_counts.ndjson\"),\n",
    "}\n",
    "\n",
    "# load doi to czi_id lut\n",
    "with open(\"../data/comm_disambiguated_cvis_count.json\") as open_f:\n",
    "    doi_to_czi_id_lut = json.load(open_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DOIs: 100%|██████████| 1000/1000 [00:20<00:00, 49.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Init graph\n",
    "graph = nx.DiGraph()\n",
    "processed_nodes = set()\n",
    "\n",
    "# Sampled DOIs\n",
    "sampled_dois = random.sample(list(doi_to_czi_id_lut.keys()), 1000)\n",
    "\n",
    "for doi in tqdm(\n",
    "    sampled_dois,\n",
    "    total=len(sampled_dois),\n",
    "    desc=\"Processing DOIs\",\n",
    "):\n",
    "    # Get normed DOI\n",
    "    norm_doi = doi.replace(\"/\", \"-\").replace(\".\", \"_\")\n",
    "\n",
    "    # Create graph\n",
    "    graph_from_czi_ids(\n",
    "        registries=registries,\n",
    "        czi_ids=doi_to_czi_id_lut[doi],\n",
    "        graph=graph,\n",
    "        processed_nodes=processed_nodes,\n",
    "        starting_node=doi,\n",
    "        starting_node_attrs={\n",
    "            \"ecosystem\": \"paper\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "# Write out graph\n",
    "nx.write_gexf(graph, \"dois-graph.gexf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czi-hack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
